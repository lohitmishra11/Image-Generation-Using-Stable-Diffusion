# -*- coding: utf-8 -*-
"""stable_diffusion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iRYZsVYaO4rv4PCungOaObk-BsAbEqo2

#**Image Generation using Stable Diffusion**

This notebook showcases a complete pipeline for generating images from text prompts using the **Stable Diffusion v1.4** model. It also tracks and visualizes key performance metrics such as **inference time**, **precision**, and **prompt history**. An interactive **Gradio UI** allows easy experimentation, while additional tools help **log, analyze, and save** the results of each generation.

# Step 1: Install Required Libraries
This step installs all the necessary libraries required to build a prompt-based image generation system using diffusion models.

- `diffusers`: For implementing and using diffusion models like Stable Diffusion.
- `transformers`: Provides pre-trained models (like CLIP) for text embeddings.
- `accelerate`: Helps run and optimize models across CPUs, GPUs, or TPUs.
- `gradio`: Used to create an interactive web UI for text-to-image generation.
- `matplotlib`: For visualizing generated images and data plots.
- `scikit-learn`: Provides machine learning utilities for evaluation and data processing.
"""

# Install required libraries
!pip install diffusers transformers accelerate gradio matplotlib scikit-learn --quiet

"""#Step 2: Import Libraries and  Load Stable Diffusion Model
**This cell performs the following tasks:**
- **Imports essential libraries** such as:
  - `gradio` for the UI,
  - `torch` for deep learning operations,
  - `matplotlib` for visualizations,
  - `diffusers` for loading the Stable Diffusion pipeline,
  - `sklearn` for evaluation metrics,
  - `IPython.display` for displaying images,
  - `numpy` for numerical operations.
- **Sets the Hugging Face authentication token** and selects the appropriate device (GPU if available, otherwise CPU).
- **Loads the pre-trained Stable Diffusion v1.4 model** with half-precision (fp16) for better performance on GPU.
- **Initializes an empty list** `inference_times` to store image generation durations for later analysis.
"""

import gradio as gr
import torch
import time
import matplotlib.pyplot as plt
from diffusers import StableDiffusionPipeline
from sklearn.metrics import precision_score, confusion_matrix, ConfusionMatrixDisplay
from IPython.display import display, Image as IPyImage
import numpy as np
import torch
import time
import pandas as pd
from sklearn.metrics import precision_score, confusion_matrix, ConfusionMatrixDisplay
from datetime import datetime
import ipywidgets as widgets
from IPython.display import display

# Token and device
auth_token = "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"
device = "cuda" if torch.cuda.is_available() else "cpu"

# Load model
pipe = StableDiffusionPipeline.from_pretrained(
    "CompVis/stable-diffusion-v1-4",
    revision="fp16",
    torch_dtype=torch.float16,
    use_auth_token=auth_token
).to(device)

inference_times = []

"""#Step 3: Define Metric Logging Function

This cell initializes a DataFrame and defines a function to log performance metrics after each image generation.

- **`metrics_log` DataFrame**: Stores logs with the following columns:
  - `"Prompt"`: The input text used for image generation.
  - `"Inference Time (s)"`: Time taken to generate the image.
  - `"Timestamp"`: Date and time of the generation.
  - `"Precision"`: A placeholder for precision score (can be computed later depending on the use case).
- **`log_metrics()` function**:
  - Accepts a prompt, inference time, and precision.
  - Generates a timestamp.
  - Adds the new entry to the global `metrics_log` DataFrame.
  - Returns the new log entry.

This setup helps in tracking and analyzing model performance over time.
"""

metrics_log = pd.DataFrame(columns=["Prompt", "Inference Time (s)", "Timestamp", "Precision"])

def log_metrics(prompt, inference_time, precision):
    global metrics_log
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    new_entry = {
        "Prompt": prompt,
        "Inference Time (s)": inference_time,
        "Timestamp": timestamp,
        "Precision": precision
    }
    metrics_log = pd.concat([metrics_log, pd.DataFrame([new_entry])], ignore_index=True)
    return new_entry

"""#Step 4: Simulate and Visualize Performance Metrics**

This cell simulates performance metrics and provides basic visualizations before actual image generation begins.

- **`inference_times` list**: Appends a dummy inference time (e.g., 11.83 seconds) for demonstration.
- **`show_performance_metrics()` function**:
  - **Plots inference times** across generations using a simple line graph.
  - **Simulates a precision score** using predefined `y_true` and `y_pred` values.
  - **Displays a confusion matrix** to visually represent prediction accuracy.
  
These visuals help understand how inference duration and precision could be tracked and evaluated during real usage.
"""

# Simulated inference and precision metrics (optional visualization before any generation)
inference_times = []

def show_performance_metrics():
    dummy_time = 11.83
    inference_times.append(dummy_time)

    # Plot inference time
    print("üìä Inference Time per Generation:")
    plt.figure(figsize=(6, 4))
    plt.plot(range(1, len(inference_times) + 1), inference_times, marker='o', color='green')
    plt.title("Inference Time per Generation")
    plt.xlabel("Run #")
    plt.ylabel("Time (seconds)")
    plt.grid(True)
    plt.show()

    # Show simulated precision matrix
    print("\nüìå Simulated Precision Matrix:")
    y_true = [1, 0, 1, 1, 0, 1]
    y_pred = [1, 0, 1, 0, 0, 1]
    precision = precision_score(y_true, y_pred)

    cm = confusion_matrix(y_true, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(cmap='viridis')
    plt.title(f"Simulated Precision Matrix (Precision: {precision:.2f})")
    plt.show()

show_performance_metrics()

"""
# Step 5: Image Generation Function with Metric Logging

This cell defines the main function to generate images from text prompts and track key performance metrics.

- **`generated_images` list**: Keeps a record of all generated image file paths.
- **`generate_image_gradio(prompt)` function**:
  - Starts a timer before image generation.
  - Uses the Stable Diffusion pipeline (`pipe`) to generate an image from the given prompt with a guidance scale of 8.5.
  - Saves the image with a unique filename and adds it to the `generated_images` list.
  - Calculates the inference duration.
  - Simulates a precision score using dummy labels.
  - Logs all relevant metrics (prompt, time, timestamp, precision) via the `log_metrics()` function.
  - Returns the generated image and a formatted string displaying the metrics.

This function integrates image generation, performance tracking, and file saving into a single workflow."""

# To track all generated image paths
generated_images = []
def generate_image_gradio(prompt):
    start = time.time()

    with torch.autocast(device):
        result = pipe(prompt, guidance_scale=8.5)
    image = result["images"][0]

    # Save with unique filename
    filename = f"generated_{int(time.time())}.png"
    image.save(filename)
    generated_images.append(filename)  # Track the filename

    end = time.time()
    duration = round(end - start, 2)

    # Simulated precision
    y_true = [1, 0, 1, 1, 0, 1]
    y_pred = [1, 0, 1, 0, 0, 1]
    precision = precision_score(y_true, y_pred)

    # Log the metrics
    log = log_metrics(prompt, duration, precision)
    metrics_text = f"""
üìù Prompt: {log['Prompt']}
‚è±Ô∏è Inference Time: {log['Inference Time (s)']}s
üìÖ Timestamp: {log['Timestamp']}
üéØ Precision: {log['Precision']:.2f}
"""
    return image, metrics_text

"""
#Step 6: Launch Gradio Web Interface

This cell sets up and launches a Gradio-based web UI for interacting with the Stable Diffusion model.

- **`gr.Interface()`** creates an interactive frontend where users can:
  - Input a custom text **prompt**.
  - View the **generated image**.
  - See **inference metrics** such as time and precision.
- The interface is titled **" Stable Diffusion Generator with Metrics"**, emphasizing both creativity and performance tracking.
- **`iface.launch()`** starts the web app directly inside the notebook or in a shareable link.

This step allows users to experiment with prompt-based image generation in a user-friendly environment."""

iface = gr.Interface(
    fn=generate_image_gradio,
    inputs=gr.Textbox(label="Enter your prompt"),
    outputs=[
        gr.Image(label="Generated Image"),
        gr.Textbox(label="Prompt Metrics", lines=5)
    ],
    title="üß† Stable Diffusion Generator with Metrics"
)

iface.launch()

"""# Step 7: View and Save Generation Metrics Log

This cell adds interactive buttons using `ipywidgets` to manage the generation metrics log:

- **üìä View Full Metrics Log Button**:
  - Displays the complete `metrics_log` DataFrame showing prompt history, inference times, timestamps, and precision scores.

- **üíæ Save Metrics to CSV Button**:
  - Saves the current `metrics_log` to a CSV file named `generation_metrics_log.csv` for future reference or offline analysis.

These tools help track and export performance insights for all image generations done during the session.
"""

# View Metrics Log Button
def show_log(b):
    display(metrics_log)

view_button = widgets.Button(description="üìä View Full Metrics Log", button_style='info')
view_button.on_click(show_log)
display(view_button)

# Save Log to CSV Button
def save_log(b):
    metrics_log.to_csv("generation_metrics_log.csv", index=False)
    print("‚úÖ Metrics log saved as generation_metrics_log.csv")

save_button = widgets.Button(description="üíæ Save Metrics to CSV", button_style='success')
save_button.on_click(save_log)
display(save_button)

"""#Step 8: Plot Inference Time Metrics

This cell introduces a button to visualize how inference time varies with different prompts:

- **`plot_metrics()` function**:
  - Plots a line graph of **Prompt vs. Inference Time** using the logged data.
  - Ensures at least **5 entries** exist in the `metrics_log` before plotting.
  - Displays a readable and interactive chart for performance comparison across prompts.

- **Plot Inference Metrics Button**:
  - Triggers the graph display when clicked, providing an at-a-glance overview of generation speed trends.

This step adds a data-driven visualization layer to evaluate system performance over multiple runs.
"""

import matplotlib.pyplot as plt
import ipywidgets as widgets

def plot_metrics():
    if len(metrics_log) >= 5:
        plt.figure(figsize=(12, 6))  # Increased height for better spacing
        plt.plot(metrics_log["Prompt"], metrics_log["Inference Time (s)"], marker='o')
        plt.title("Prompt vs Inference Time")
        plt.xlabel("Prompt")
        plt.ylabel("Inference Time (s)")
        plt.xticks(rotation=60, ha='right')  # Rotate and align labels
        plt.grid(True)
        plt.subplots_adjust(bottom=0.3)  # Adjust space at bottom
        plt.tight_layout()
        plt.show()
    else:
        print(f"Generate at least 5 prompts to see graph. Current: {len(metrics_log)}")

# Create and display the button
plot_button = widgets.Button(description="üìà Plot Inference Metrics", button_style='warning')
plot_button.on_click(lambda b: plot_metrics())
display(plot_button)

"""
# Step 9: Display All Generated Images

This cell provides a button to view all previously generated images in one place:

- **`show_all_images()` function**:
  - Checks if any images have been generated.
  - If yes, displays all images stored in the `generated_images` list using `IPython.display.Image`.

- **Show All Generated Images Button**:
  - On click, it launches a visual gallery of all the outputs generated so far.

This final step gives a convenient way to review and reflect on all image generations during the session."""

from IPython.display import HTML, display
import base64

def show_all_images(b):
    if not generated_images:
        print("No images generated yet.")
    else:
        print(f"üñºÔ∏è Showing {len(generated_images)} generated images:")

        img_tags = ""
        for img_path in generated_images:
            try:
                with open(img_path, "rb") as img_file:
                    img_data = base64.b64encode(img_file.read()).decode("utf-8")
                    img_tags += f'<img src="data:image/png;base64,{img_data}" style="margin:10px; width:250px; height:auto; display:inline-block;">'
            except Exception as e:
                print(f"‚ö†Ô∏è Could not load image {img_path}: {e}")

        display(HTML(f"<div style='display:flex; flex-wrap:wrap;'>{img_tags}</div>"))

gallery_button = widgets.Button(description="üñºÔ∏è Show All Generated Images", button_style='primary')
gallery_button.on_click(show_all_images)
display(gallery_button)